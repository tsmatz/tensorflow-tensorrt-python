{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib import tensorrt as trt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constants (parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1 # change to 128 when you use batch\n",
    "workspace_size_bytes = 1 << 30\n",
    "precision_mode = 'FP16' # use 'FP32' for K80\n",
    "trt_gpu_ops = tf.GPUOptions(per_process_gpu_memory_fraction = 0.50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform images (image -> input vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded image vectors (tiger, lion, orangutan)\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "g1 = tf.Graph()\n",
    "with g1.as_default():\n",
    "    #\n",
    "    # Create graph\n",
    "    #\n",
    "    in_images = tf.placeholder(tf.string, name='in_images')\n",
    "    decoded_input = tf.image.decode_png(in_images, channels=3)\n",
    "    float_input = tf.cast(decoded_input, dtype=tf.float32)\n",
    "    # (224, 224, 3) -> (n, 224, 224, 3)\n",
    "    rgb_input = tf.expand_dims(\n",
    "        float_input,\n",
    "        axis=0)\n",
    "    # For VGG preprocess, reduce means and convert to BGR\n",
    "    slice_red = tf.slice(\n",
    "        rgb_input,\n",
    "        [0, 0, 0, 0],\n",
    "        [1, 224, 224, 1])\n",
    "    slice_green = tf.slice(\n",
    "        rgb_input,\n",
    "        [0, 0, 0, 1],\n",
    "        [1, 224, 224, 1])\n",
    "    slice_blue = tf.slice(\n",
    "        rgb_input,\n",
    "        [0, 0, 0, 2],\n",
    "        [1, 224, 224, 1])\n",
    "    sub_red = tf.subtract(slice_red, 123.68)\n",
    "    sub_green = tf.subtract(slice_green, 116.779)\n",
    "    sub_blue = tf.subtract(slice_blue, 103.939)\n",
    "    transferred_input = tf.concat(\n",
    "        [sub_blue, sub_green, sub_red],\n",
    "        3)\n",
    "    #\n",
    "    # Transform to vectors\n",
    "    #\n",
    "    with tf.Session(config=tf.ConfigProto(gpu_options=trt_gpu_ops)) as s1:\n",
    "        with open('./tiger224x224.jpg', 'rb') as f:\n",
    "            data1 = f.read()\n",
    "            feed_dict = {\n",
    "                in_images: data1\n",
    "            }\n",
    "            imglist1 = s1.run([transferred_input], feed_dict=feed_dict)\n",
    "            image1 = imglist1[0]\n",
    "        with open('./lion224x224.jpg', 'rb') as f:\n",
    "            data2 = f.read()\n",
    "            feed_dict = {\n",
    "                in_images: data2\n",
    "            }\n",
    "            imglist2 = s1.run([transferred_input], feed_dict=feed_dict)\n",
    "            image2 = imglist2[0]\n",
    "        with open('./orangutan224x224.jpg', 'rb') as f:\n",
    "            data3 = f.read()\n",
    "            feed_dict = {\n",
    "                in_images: data3\n",
    "            }\n",
    "            imglist3 = s1.run([transferred_input], feed_dict=feed_dict)\n",
    "            image3 = imglist3[0]\n",
    "print('Loaded image vectors (tiger, lion, orangutan)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Batch Test\n",
    "When you test batch, please uncomment here. (Single prediction is executed by default.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image1 = np.tile(image1,(batch_size,1,1,1))\n",
    "# image2 = np.tile(image2,(batch_size,1,1,1))\n",
    "# image3 = np.tile(image3,(batch_size,1,1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load classification graph def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded classifier graph def\n"
     ]
    }
   ],
   "source": [
    "classifier_model_file = './resnetV150_frozen.pb'\n",
    "classifier_graph_def = tf.GraphDef()\n",
    "with tf.gfile.Open(classifier_model_file, 'rb') as f:\n",
    "    data = f.read()\n",
    "    classifier_graph_def.ParseFromString(data)\n",
    "print('Loaded classifier graph def')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to TensorRT graph def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated TensorRT graph def\n"
     ]
    }
   ],
   "source": [
    "trt_graph_def = trt.create_inference_graph(\n",
    "    input_graph_def=classifier_graph_def,\n",
    "    outputs=['resnet_v1_50/predictions/Reshape_1'],\n",
    "    max_batch_size=batch_size,\n",
    "    max_workspace_size_bytes=workspace_size_bytes,\n",
    "    precision_mode=precision_mode)\n",
    "#trt_graph_def=trt.calib_graph_to_infer_graph(trt_graph_def) # For only 'INT8'\n",
    "print('Generated TensorRT graph def')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate tensor with TensorRT graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated tensor by TensorRT graph\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph()\n",
    "g2 = tf.Graph()\n",
    "with g2.as_default():\n",
    "    trt_x, trt_y = tf.import_graph_def(\n",
    "        trt_graph_def,\n",
    "        return_elements=['input:0', 'resnet_v1_50/predictions/Reshape_1:0'])\n",
    "    print('Generated tensor by TensorRT graph')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run classification with TensorRT graph\n",
    "Here we benchmark the inference performance by resnet50 model with TensorRT graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********************\n",
      "b'tiger, Panthera tigris' confidence: 0.9248719\n",
      "b'tiger cat' confidence: 0.070364535\n",
      "b'zebra' confidence: 0.0017802829\n",
      "b'tabby, tabby cat' confidence: 0.0015412017\n",
      "b'jaguar, panther, Panthera onca, Felis onca' confidence: 0.0006885257\n",
      "1638.52 milliseconds\n",
      "********************\n",
      "b'lion, king of beasts, Panthera leo' confidence: 0.5414057\n",
      "b'cougar, puma, catamount, mountain lion, painter, panther, Felis concolor' confidence: 0.4447845\n",
      "b'wombat' confidence: 0.0017796681\n",
      "b'jaguar, panther, Panthera onca, Felis onca' confidence: 0.0015732109\n",
      "b'tiger, Panthera tigris' confidence: 0.0011850431\n",
      "6.13 milliseconds\n",
      "********************\n",
      "b'orangutan, orang, orangutang, Pongo pygmaeus' confidence: 0.82951844\n",
      "b'gorilla, Gorilla gorilla' confidence: 0.13274863\n",
      "b'chimpanzee, chimp, Pan troglodytes' confidence: 0.0357832\n",
      "b'macaque' confidence: 0.0007095223\n",
      "b'patas, hussar monkey, Erythrocebus patas' confidence: 0.0002844938\n",
      "5.83 milliseconds\n"
     ]
    }
   ],
   "source": [
    "with open('./imagenet_classes.txt', 'rb') as f:\n",
    "    labeltext = f.read()\n",
    "    classes_entries = labeltext.splitlines()\n",
    "with tf.Session(graph=g2, config=tf.ConfigProto(gpu_options=trt_gpu_ops)) as s2:\n",
    "    #\n",
    "    # predict image1 (tiger)\n",
    "    #\n",
    "    feed_dict = {\n",
    "        trt_x: image1\n",
    "    }\n",
    "    start_time = time.process_time()\n",
    "    result = s2.run([trt_y], feed_dict=feed_dict)\n",
    "    stop_time = time.process_time()\n",
    "    # list -> 1 x n ndarray : feature's format is [[1.16643378e-06 3.12126781e-06 3.39836406e-05 ... ]]\n",
    "    nd_result = result[0]\n",
    "    # remove row's dimension\n",
    "    onedim_result = nd_result[0,]\n",
    "    # set column index to array of possibilities \n",
    "    indexed_result = enumerate(onedim_result)\n",
    "    # sort with possibilities\n",
    "    sorted_result = sorted(indexed_result, key=lambda x: x[1], reverse=True)\n",
    "    # get the names of top 5 possibilities\n",
    "    print('********************')\n",
    "    for top in sorted_result[:5]:\n",
    "        print(classes_entries[top[0]], 'confidence:', top[1])\n",
    "    print('{:.2f} milliseconds'.format((stop_time-start_time)*1000))\n",
    "    #\n",
    "    # predict image2 (lion)\n",
    "    #\n",
    "    feed_dict = {\n",
    "        trt_x: image2\n",
    "    }\n",
    "    start_time = time.process_time()\n",
    "    result = s2.run([trt_y], feed_dict=feed_dict)\n",
    "    stop_time = time.process_time()\n",
    "    # list -> 1 x n ndarray : feature's format is [[1.16643378e-06 3.12126781e-06 3.39836406e-05 ... ]]\n",
    "    nd_result = result[0]\n",
    "    # remove row's dimension\n",
    "    onedim_result = nd_result[0,]\n",
    "    # set column index to array of possibilities \n",
    "    indexed_result = enumerate(onedim_result)\n",
    "    # sort with possibilities\n",
    "    sorted_result = sorted(indexed_result, key=lambda x: x[1], reverse=True)\n",
    "    # get the names of top 5 possibilities\n",
    "    print('********************')\n",
    "    for top in sorted_result[:5]:\n",
    "        print(classes_entries[top[0]], 'confidence:', top[1])\n",
    "    print('{:.2f} milliseconds'.format((stop_time-start_time)*1000))\n",
    "    #\n",
    "    # predict image3 (orangutan)\n",
    "    #\n",
    "    feed_dict = {\n",
    "        trt_x: image3\n",
    "    }\n",
    "    start_time = time.process_time()\n",
    "    result = s2.run([trt_y], feed_dict=feed_dict)\n",
    "    stop_time = time.process_time()\n",
    "    # list -> 1 x n ndarray : feature's format is [[1.16643378e-06 3.12126781e-06 3.39836406e-05 ... ]]\n",
    "    nd_result = result[0]\n",
    "    # remove row's dimension\n",
    "    onedim_result = nd_result[0,]\n",
    "    # set column index to array of possibilities \n",
    "    indexed_result = enumerate(onedim_result)\n",
    "    # sort with possibilities\n",
    "    sorted_result = sorted(indexed_result, key=lambda x: x[1], reverse=True)\n",
    "    # get the names of top 5 possibilities\n",
    "    print('********************')\n",
    "    for top in sorted_result[:5]:\n",
    "        print(classes_entries[top[0]], 'confidence:', top[1])\n",
    "    print('{:.2f} milliseconds'.format((stop_time-start_time)*1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
